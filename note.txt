
# Creating a CNN-based image classifier.
class ImageClassifier(nn.Module):
    def __init__(self):
        super().__init__()
        
        # First block - efficient feature extraction
        self.conv_block1 = nn.Sequential(
            nn.Conv2d(3, 16, 3, stride=2, padding=1),  # Stride 2 reduces spatial dimensions early
            nn.ReLU(),
            nn.BatchNorm2d(16)
        )
        
        # Second block - moderate feature expansion
        self.conv_block2 = nn.Sequential(
            nn.Conv2d(16, 32, 3, stride=2, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(32)
        )
        
        # Third block - final feature extraction
        self.conv_block3 = nn.Sequential(
            nn.Conv2d(32, 48, 3, stride=2, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(48)
        )
        
        # Global Average Pooling
        self.global_pool = nn.AdaptiveAvgPool2d(1)
        
        # Simple classifier
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(48, 2)
        )
        
    def forward(self, x):
        x = self.conv_block1(x)
        x = self.conv_block2(x)
        x = self.conv_block3(x)
        x = self.global_pool(x)
        x = self.classifier(x)
        return x

# Instantiate model
model = ImageClassifier().to(device)

Epoch: 1 | train_loss: 0.6460 | train_acc: 0.6185 | val_loss: 0.6326 | val_acc: 0.6163
Epoch: 2 | train_loss: 0.6047 | train_acc: 0.6680 | val_loss: 0.5918 | val_acc: 0.6820
Epoch: 3 | train_loss: 0.5691 | train_acc: 0.7057 | val_loss: 0.5625 | val_acc: 0.7136
Epoch: 4 | train_loss: 0.5463 | train_acc: 0.7261 | val_loss: 0.5562 | val_acc: 0.7215
Epoch: 6 | train_loss: 0.5122 | train_acc: 0.7511 | val_loss: 0.5424 | val_acc: 0.7294
Epoch: 7 | train_loss: 0.4957 | train_acc: 0.7630 | val_loss: 0.5214 | val_acc: 0.7413
Epoch: 8 | train_loss: 0.4786 | train_acc: 0.7745 | val_loss: 0.5025 | val_acc: 0.7516
Epoch: 9 | train_loss: 0.4602 | train_acc: 0.7855 | val_loss: 0.4826 | val_acc: 0.7690
Epoch: 10 | train_loss: 0.4392 | train_acc: 0.7981 | val_loss: 0.4724 | val_acc: 0.7733
Epoch: 11 | train_loss: 0.4192 | train_acc: 0.8116 | val_loss: 0.4536 | val_acc: 0.7927
Epoch: 12 | train_loss: 0.4003 | train_acc: 0.8217 | val_loss: 0.4474 | val_acc: 0.7994
Epoch: 13 | train_loss: 0.3841 | train_acc: 0.8315 | val_loss: 0.4388 | val_acc: 0.8070


------------------------------------------------------------------------------------------------

# Creating a CNN-based image classifier.
class ImageClassifier(nn.Module):
    def __init__(self):
        super().__init__()
        
        # Single efficient initial conv with aggressive stride
        self.conv1 = nn.Sequential(
            nn.Conv2d(3, 8, 7, stride=4, padding=3),  # Aggressive stride to reduce dimensions
            nn.ReLU(),
            nn.BatchNorm2d(8)
        )
        
        # Minimal second conv
        self.conv2 = nn.Sequential(
            nn.Conv2d(8, 16, 3, stride=2, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(16)
        )
        
        # Global pooling and classifier
        self.global_pool = nn.AdaptiveAvgPool2d(1)
        self.classifier = nn.Linear(16, 2)
        
    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.global_pool(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x

# Instantiate model
model = ImageClassifier().to(device)

Epoch: 1 | train_loss: 0.6492 | train_acc: 0.6128 | val_loss: 0.6331 | val_acc: 0.6321
Epoch: 2 | train_loss: 0.6321 | train_acc: 0.6356 | val_loss: 0.6152 | val_acc: 0.6392
Epoch: 3 | train_loss: 0.6205 | train_acc: 0.6531 | val_loss: 0.6138 | val_acc: 0.6566
Epoch: 4 | train_loss: 0.6063 | train_acc: 0.6722 | val_loss: 0.5933 | val_acc: 0.6741
Epoch: 5 | train_loss: 0.5933 | train_acc: 0.6852 | val_loss: 0.5840 | val_acc: 0.6907
Epoch: 6 | train_loss: 0.5784 | train_acc: 0.6964 | val_loss: 0.5705 | val_acc: 0.6950
Epoch: 7 | train_loss: 0.5677 | train_acc: 0.7047 | val_loss: 0.5625 | val_acc: 0.7120
Epoch: 8 | train_loss: 0.5569 | train_acc: 0.7151 | val_loss: 0.5510 | val_acc: 0.7207
Epoch: 9 | train_loss: 0.5493 | train_acc: 0.7195 | val_loss: 0.5451 | val_acc: 0.7278
Epoch: 11 | train_loss: 0.5362 | train_acc: 0.7323 | val_loss: 0.5383 | val_acc: 0.7282
Epoch: 12 | train_loss: 0.5326 | train_acc: 0.7365 | val_loss: 0.5322 | val_acc: 0.7369
Epoch: 14 | train_loss: 0.5257 | train_acc: 0.7403 | val_loss: 0.5261 | val_acc: 0.7476
Epoch: 15 | train_loss: 0.5226 | train_acc: 0.7448 | val_loss: 0.5247 | val_acc: 0.7496
Epoch: 17 | train_loss: 0.5159 | train_acc: 0.7484 | val_loss: 0.5222 | val_acc: 0.7500
Epoch: 18 | train_loss: 0.5132 | train_acc: 0.7493 | val_loss: 0.5170 | val_acc: 0.7555
Epoch: 20 | train_loss: 0.5082 | train_acc: 0.7537 | val_loss: 0.5125 | val_acc: 0.7587
Epoch: 21 | train_loss: 0.5050 | train_acc: 0.7561 | val_loss: 0.5088 | val_acc: 0.7611
Epoch: 22 | train_loss: 0.5022 | train_acc: 0.7567 | val_loss: 0.5061 | val_acc: 0.7654
Epoch: 23 | train_loss: 0.4998 | train_acc: 0.7571 | val_loss: 0.5047 | val_acc: 0.7658
Epoch: 26 | train_loss: 0.4926 | train_acc: 0.7623 | val_loss: 0.4994 | val_acc: 0.7682
Epoch: 30 | train_loss: 0.4839 | train_acc: 0.7685 | val_loss: 0.4977 | val_acc: 0.7686
Epoch: 33 | train_loss: 0.4777 | train_acc: 0.7730 | val_loss: 0.4955 | val_acc: 0.7706
Epoch: 41 | train_loss: 0.4651 | train_acc: 0.7834 | val_loss: 0.4942 | val_acc: 0.7722

------------------------------------------------------------------------------------------------
class ImageClassifier(nn.Module):
    def __init__(self):
        super().__init__()
        
        # More channels, smaller stride
        self.conv1 = nn.Sequential(
            nn.Conv2d(3, 32, 7, stride=2, padding=3),
            nn.ReLU(),
            nn.BatchNorm2d(32),
            nn.MaxPool2d(2)
        )
        
        # Add more conv layers with increasing channels
        self.conv2 = nn.Sequential(
            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(64),
            nn.MaxPool2d(2)
        )
        
        self.conv3 = nn.Sequential(
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.BatchNorm2d(128)
        )
        
        self.global_pool = nn.AdaptiveAvgPool2d(1)
        self.classifier = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(128, 2)
        )
        
    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.global_pool(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x

# Instantiate model
model = ImageClassifier().to(device)

Epoch: 1 | train_loss: 0.6264 | train_acc: 0.6463 | val_loss: 0.6016 | val_acc: 0.6726
Epoch: 5 | train_loss: 0.4913 | train_acc: 0.7683 | val_loss: 0.5463 | val_acc: 0.7272
Epoch: 7 | train_loss: 0.3987 | train_acc: 0.8279 | val_loss: 0.4049 | val_acc: 0.8280
Epoch: 9 | train_loss: 0.3246 | train_acc: 0.8642 | val_loss: 0.3486 | val_acc: 0.8447
Epoch: 10 | train_loss: 0.2940 | train_acc: 0.8800 | val_loss: 0.3418 | val_acc: 0.8584
Epoch: 11 | train_loss: 0.2728 | train_acc: 0.8888 | val_loss: 0.3314 | val_acc: 0.8661
Epoch: 13 | train_loss: 0.2336 | train_acc: 0.9044 | val_loss: 0.2904 | val_acc: 0.8887